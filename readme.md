<h1 align="center">AI Tools</h1>

<div style="display: flex; gap: 4rem; width: 100%; justify-content: center; font-size: x-large; align-items: center;" data-astro-cid-d5b6c6e3=""> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 -10 80 128" fill="none" width="80" height="80"> <path d="M27.5893 91.1365C22.7555 86.7178 21.3443 77.4335 23.3583 70.7072C26.8503 74.948 31.6888 76.2914 36.7005 77.0497C44.4374 78.2199 52.0358 77.7822 59.2231 74.2459C60.0453 73.841 60.8052 73.3027 61.7036 72.7574C62.378 74.714 62.5535 76.6892 62.3179 78.6996C61.7452 83.5957 59.3086 87.3778 55.4332 90.2448C53.8835 91.3916 52.2437 92.4167 50.6432 93.4979C45.7262 96.8213 44.3959 100.718 46.2435 106.386C46.2874 106.525 46.3267 106.663 46.426 107C43.9155 105.876 42.0817 104.24 40.6844 102.089C39.2086 99.8193 38.5065 97.3081 38.4696 94.5909C38.4511 93.2686 38.4511 91.9345 38.2733 90.6309C37.8391 87.4527 36.3471 86.0297 33.5364 85.9478C30.6518 85.8636 28.37 87.6469 27.7649 90.4554C27.7187 90.6707 27.6517 90.8837 27.5847 91.1341L27.5893 91.1365Z" fill="currentColor"></path> <path d="M0 69.5866C0 69.5866 14.3139 62.6137 28.6678 62.6137L39.4901 29.1204C39.8953 27.5007 41.0783 26.3999 42.4139 26.3999C43.7495 26.3999 44.9325 27.5007 45.3377 29.1204L56.1601 62.6137C73.1601 62.6137 84.8278 69.5866 84.8278 69.5866C84.8278 69.5866 60.5145 3.35233 60.467 3.21944C59.7692 1.2612 58.5911 0 57.0029 0H27.8274C26.2392 0 25.1087 1.2612 24.3634 3.21944C24.3108 3.34983 0 69.5866 0 69.5866Z" fill="currentColor"></path> </svg> <p data-astro-cid-d5b6c6e3="">+</p> <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" xmlns:xlink="http://www.w3.org/1999/xlink" width="80" height="80"> <g id="logo" transform="translate(53, 53)"> <path id="r" transform="translate(0.5, 0.5)" stroke-width="1" stroke-linejoin="round" fill="currentColor" d="     M -9,-15 H 4 C 12,-15 12,-7 4,-7 H -9 Z     M -40,22 H 0 V 11 H -9 V 3 H 1 C 12,3 6,22 15,22 H 40     V 3 H 34 V 5 C 34,13 25,12 24,7 C 23,2 19,-2 18,-2 C 33,-10 24,-26 12,-26 H -35     V -15 H -25 V 11 H -40 Z"></path> <g id="gear" mask="url(#holes)"> <circle r="43" fill="none" stroke-width="9"></circle> <g id="cogs"> <polygon id="cog" stroke-width="3" stroke-linejoin="round" fill="currentColor" points="46,3 51,0 46,-3"></polygon> <use xlink:href="#cog" transform="rotate(11.25)"></use> <use xlink:href="#cog" transform="rotate(22.50)"></use> <use xlink:href="#cog" transform="rotate(33.75)"></use> <use xlink:href="#cog" transform="rotate(45.00)"></use> <use xlink:href="#cog" transform="rotate(56.25)"></use> <use xlink:href="#cog" transform="rotate(67.50)"></use> <use xlink:href="#cog" transform="rotate(78.75)"></use> <use xlink:href="#cog" transform="rotate(90.00)"></use> <use xlink:href="#cog" transform="rotate(101.25)"></use> <use xlink:href="#cog" transform="rotate(112.50)"></use> <use xlink:href="#cog" transform="rotate(123.75)"></use> <use xlink:href="#cog" transform="rotate(135.00)"></use> <use xlink:href="#cog" transform="rotate(146.25)"></use> <use xlink:href="#cog" transform="rotate(157.50)"></use> <use xlink:href="#cog" transform="rotate(168.75)"></use> <use xlink:href="#cog" transform="rotate(180.00)"></use> <use xlink:href="#cog" transform="rotate(191.25)"></use> <use xlink:href="#cog" transform="rotate(202.50)"></use> <use xlink:href="#cog" transform="rotate(213.75)"></use> <use xlink:href="#cog" transform="rotate(225.00)"></use> <use xlink:href="#cog" transform="rotate(236.25)"></use> <use xlink:href="#cog" transform="rotate(247.50)"></use> <use xlink:href="#cog" transform="rotate(258.75)"></use> <use xlink:href="#cog" transform="rotate(270.00)"></use> <use xlink:href="#cog" transform="rotate(281.25)"></use> <use xlink:href="#cog" transform="rotate(292.50)"></use> <use xlink:href="#cog" transform="rotate(303.75)"></use> <use xlink:href="#cog" transform="rotate(315.00)"></use> <use xlink:href="#cog" transform="rotate(326.25)"></use> <use xlink:href="#cog" transform="rotate(337.50)"></use> <use xlink:href="#cog" transform="rotate(348.75)"></use> </g> <g id="mounts"> <polygon id="mount" stroke-width="6" stroke-linejoin="round" fill="currentColor" points="-7,-42 0,-35 7,-42"></polygon> <use xlink:href="#mount" transform="rotate(72)"></use> <use xlink:href="#mount" transform="rotate(144)"></use> <use xlink:href="#mount" transform="rotate(216)"></use> <use xlink:href="#mount" transform="rotate(288)"></use> </g> </g> <mask id="holes"> <rect x="-60" y="-60" width="120" height="120" fill="white"></rect> <circle id="hole" cy="-40" r="3"></circle> <use xlink:href="#hole" transform="rotate(72)"></use> <use xlink:href="#hole" transform="rotate(144)"></use> <use xlink:href="#hole" transform="rotate(216)"></use> <use xlink:href="#hole" transform="rotate(288)"></use> </mask> </g> </svg> <div class="box" data-astro-cid-d5b6c6e3=""> <h2 data-astro-cid-d5b6c6e3="">
ðŸ¦€ A comprehensive web application for managing and testing LLM workflows with llama.cpp, vector databases, and AI agents.
</h2> </div> </div>

<p>
  <img alt="Version" src="https://img.shields.io/badge/version-0.1.0-blue.svg?cacheSeconds=2592000" />
  <a href="#" target="_blank">
    <img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg" />
  </a>
</p>

**Platforms**

![windows](https://img.shields.io/badge/Platform-Windows-blue)
![linux](https://img.shields.io/badge/Platform-Linux-blue)
![macOs](https://img.shields.io/badge/Platform-MacOs-blue)

## Overview

**AI Tools** is a tester and companion web application designed to help you manage, test, and interact with local LLM infrastructure. It provides a comprehensive web UI for working with llama.cpp servers, vector databases, implment you own personal AI agent, and various data conversion tools.

## Prerequisites

Before using AI Tools, you need to install the following dependencies separately:

1. **llama.cpp** - Must be installed and available as a binary command (`llama-server` must be in your PATH)
   - The application will scan for GGUF models in `~/.cache/llama.cpp/`
   - You can download and build llama.cpp from: https://github.com/ggerganov/llama.cpp

2. **Ollama** - Required for embedding model generation (used by the Vector DB features)
   - Install from: https://ollama.ai/
   - Used for generating embeddings when vectorizing documents

3. **ChromaDB** - Local vector database (optional, for Vector DB features)
   - Can be run locally or connected to a remote instance

## Getting Started

To start developing with AI Tools, you will need:
- `rustc` > 1.74
- `node` > 20.9.0

Clone the project and execute:

```bash
cargo run
```

The interactive CLI will guide you through the installation process.

## Features

### 1. Llama.cpp Server Management

A comprehensive web UI for managing and testing llama.cpp server instances:

- **Model Management**: Scan and select from available GGUF models in your cache directory
- **Server Control**: Start, stop, and monitor llama.cpp server instances
- **Configuration UI**: Configure all llama.cpp server options through the web interface:
  - Context size
  - GPU layers (GPU splitting support)
  - Threads and batch processing
  - Memory mapping options
  - Flash attention
  - And many more advanced options
- **Real-time Logs**: View server output and logs in real-time through the web interface
- **Model Selection**: Choose from HuggingFace format models (e.g., `user/model:quant`)

### 2. AI Agent

A Rust-based AI agent implementation with extensible tool system:

- **Tool System**: Switch tools on/off dynamically
  - **ChromaDB Tool**: Vector database search integration
  - **Extensible Architecture**: Easy to add new tools
- **Conversation Management**: Persistent conversation history using SQLite
- **WebSocket Support**: Real-time streaming responses
- **Memory Management**: SQLite-based memory system for conversation context
- **Tool Registry**: Centralized tool registration and selection system

### 3. Vector Database (ChromaDB)

A local ChromaDB client with comprehensive management features:

- **Collection Management**: Create, configure, and manage vector collections
- **Embedding Models**: 
  - Configure different embedding models via web UI
  - Uses Ollama for embedding generation (requires Ollama installation)
  - Support for various embedding strategies
- **Document Upload**: 
  - Upload and vectorize documents with automatic embedding generation
  - Support for different vectorization strategies
  - Metadata management
- **Query Interface**: 
  - Semantic search across collections
  - Configurable result limits and filters
  - Distance metrics (Cosine, L2, IP)
- **Configuration**: Web UI for configuring collections, embedding models, and connection settings

### 4. Tools Page

A collection of useful data conversion and processing tools:

- **URL to Markdown**: Convert web pages to markdown format
- **HTML to Markdown**: Paste HTML content and convert to markdown
- **PDF to Markdown**: Upload PDF files and extract content as markdown
- **JSON to TOON**: Convert JSON data to TOON format for LLM consumption
- **Text to Tokens**: Count tokens in any text using GPT-2 tokenizer

## Architecture

### Backend (Rust + Actix)

- **API Routes**: RESTful API for all features
- **WebSocket Support**: Real-time communication for agent interactions and server logs
- **Service Layer**: Modular service architecture
- **Tool System**: Pluggable tool architecture for agent capabilities

### Frontend (Astro + Svelte)

- **Component-Based**: Modular Svelte components
- **TypeScript**: Full type safety
- **Modern UI**: Responsive and intuitive interface
- **Real-time Updates**: WebSocket integration for live data

## Project Structure

```bash
ai_tools
â”œâ”€ src
â”‚  â”œâ”€ backend          # Actix backend (Rust)
â”‚  â”‚  â”œâ”€ src
â”‚  â”‚  â”‚  â”œâ”€ api
â”‚  â”‚  â”‚  â”‚  â”œâ”€ agent          # AI agent implementation
â”‚  â”‚  â”‚  â”‚  â”‚  â”œâ”€ tools       # Tool system (ChromaDB, etc.)
â”‚  â”‚  â”‚  â”‚  â”œâ”€ llama_server   # Llama.cpp server management
â”‚  â”‚  â”‚  â”‚  â”œâ”€ chromadb       # ChromaDB client and operations
â”‚  â”‚  â”‚  â”‚  â””â”€ tools          # Data conversion tools API
â”‚  â”‚  â”‚  â””â”€ main.rs
â”‚  â”‚  â””â”€ Cargo.toml
â”‚  â”œâ”€ frontend         # Astro frontend
â”‚  â”‚  â”œâ”€ src
â”‚  â”‚  â”‚  â”œâ”€ components
â”‚  â”‚  â”‚  â”‚  â”œâ”€ agent          # Agent chat interface
â”‚  â”‚  â”‚  â”‚  â”œâ”€ llamaServer    # Llama.cpp server UI
â”‚  â”‚  â”‚  â”‚  â”œâ”€ chromadb       # Vector DB management UI
â”‚  â”‚  â”‚  â”‚  â””â”€ tools          # Conversion tools UI
â”‚  â”‚  â”‚  â”œâ”€ pages
â”‚  â”‚  â”‚  â”‚  â”œâ”€ agent.astro    # Agent page
â”‚  â”‚  â”‚  â”‚  â”œâ”€ database.astro # Vector DB page
â”‚  â”‚  â”‚  â”‚  â””â”€ tools.astro    # Tools page
â”‚  â”‚  â”‚  â””â”€ ...
â”‚  â”‚  â””â”€ package.json
â”‚  â””â”€ main.rs          # CLI entry point
â”œâ”€ Cargo.toml
â””â”€ readme.md
```

## Development

### Running the Application

```bash
# Development mode (with hot reload)
cargo run

# Production build
cargo run -- --build
cargo run -- --serve
```

### CLI Arguments

```sh
--help              # Print help message
--build             # Build production bundle
--serve             # Start production server
--test              # Run tests
--host="127.0.0.1"  # Server host address
--port=8080         # Backend port number
--env=prod/dev      # Environment mode
```

## Technology Stack

**Backend:**
- Rust
- Actix Web
- SQLite (for agent memory)
- ChromaDB client

**Frontend:**
- Astro
- Svelte
- TypeScript
- Vitest (testing)

**Chroma**
- ChromaDB server (via npm)


**External Dependencies:**
- llama.cpp (llama-server binary)
- Ollama (for embeddings)

## License

MIT
